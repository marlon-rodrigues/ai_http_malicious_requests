{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas\n",
    "import numpy\n",
    "import optparse\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8266</th>\n",
       "      <td>{\"searchText=%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>{\"searchText=modo=registro&amp;login=naresh&amp;passwo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7453</th>\n",
       "      <td>{\"searchText=modo=registro&amp;login=vish&amp;password...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7189</th>\n",
       "      <td>{\"searchText=modo=registro&amp;login=ansorger&amp;pass...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13965</th>\n",
       "      <td>{\"searchText=&amp;tenantKey=61&amp;timeRangeScalar=1&amp;t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0  1\n",
       "8266   {\"searchText=%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e...  1\n",
       "535    {\"searchText=modo=registro&login=naresh&passwo...  0\n",
       "7453   {\"searchText=modo=registro&login=vish&password...  0\n",
       "7189   {\"searchText=modo=registro&login=ansorger&pass...  0\n",
       "13965  {\"searchText=&tenantKey=61&timeRangeScalar=1&t...  1"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests_data = pandas.read_csv('Datasets/all_requests_csv_formatted_v3.csv', engine='python', quotechar='|', error_bad_lines=False, header=None)\n",
    "requests_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['{\"searchText=errorMsg=Credenciales+incorrectas&tenantKey=61&timeRangeScalar=1&timeRangeField=hours&timeRangeType=Last&timeRangeStart=&timeRangeEnd=&indexes=&filters=&resultSize=30\"}',\n",
       "        0],\n",
       "       ['{\"searchText=id=2&tenantKey=61&timeRangeScalar=1&timeRangeField=hours&timeRangeType=Last&timeRangeStart=&timeRangeEnd=&indexes=&filters=&resultSize=30\"}',\n",
       "        0],\n",
       "       ['{\"searchText=&tenantKey=61&timeRangeScalar=1&timeRangeField=hours&timeRangeType=Last&timeRangeStart=&timeRangeEnd=&indexes=&filters=%22%3e%3cscript%3ealert(1)%3c%2fscript%3e&resultSize=30\"}',\n",
       "        1],\n",
       "       ...,\n",
       "       ['{\"searchText=modo=entrar&login=delbert&pwd=08enmand15a&remember=on&B1=Entrar&tenantKey=61&timeRangeScalar=1&timeRangeField=hours&timeRangeType=Last&timeRangeStart=&timeRangeEnd=&indexes=&filters=&resultSize=30\"}',\n",
       "        0],\n",
       "       ['{\"searchText=%25%5c%2e%2e%25%5c%2e%2e%25%5c%2e%2e%25%5c%2e%2e%25%5c%2e%2e%25%5c%2e%2e%25%5c%2e%2e%25%5c%2e%2e%25%5c%2e%2e%25%5c%2e%2e%25%5c%2e%2e%25%5c%2e%2e%%20%20%20%2025%5c%2e%2e%25%5c%2e%2e%255cboot%2eini&tenantKey=61&timeRangeScalar=1&timeRangeField=hours&timeRangeType=Last&timeRangeStart=&timeRangeEnd=&indexes=&filters=&resultSize=30\"}',\n",
       "        1],\n",
       "       ['{\"searchText=&tenantKey=61&timeRangeScalar=1&timeRangeField=hours&timeRangeType=Last&timeRangeStart=&timeRangeEnd=&indexes=&filters=%2f%2e%2f%5c%2f%2e%2f%2e%2f%5c%2f%2e%2f%2e%2f%5c%2f%2e%2f%7bFILE%7d&resultSize=30\"}',\n",
       "        1]], dtype=object)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = requests_data.sample(frac=1).values # convert data into array\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['{\"searchText=errorMsg=Credenciales+incorrectas&tenantKey=61&timeRangeScalar=1&timeRangeField=hours&timeRangeType=Last&timeRangeStart=&timeRangeEnd=&indexes=&filters=&resultSize=30\"}',\n",
       "       '{\"searchText=id=2&tenantKey=61&timeRangeScalar=1&timeRangeField=hours&timeRangeType=Last&timeRangeStart=&timeRangeEnd=&indexes=&filters=&resultSize=30\"}',\n",
       "       '{\"searchText=&tenantKey=61&timeRangeScalar=1&timeRangeField=hours&timeRangeType=Last&timeRangeStart=&timeRangeEnd=&indexes=&filters=%22%3e%3cscript%3ealert(1)%3c%2fscript%3e&resultSize=30\"}',\n",
       "       ...,\n",
       "       '{\"searchText=modo=entrar&login=delbert&pwd=08enmand15a&remember=on&B1=Entrar&tenantKey=61&timeRangeScalar=1&timeRangeField=hours&timeRangeType=Last&timeRangeStart=&timeRangeEnd=&indexes=&filters=&resultSize=30\"}',\n",
       "       '{\"searchText=%25%5c%2e%2e%25%5c%2e%2e%25%5c%2e%2e%25%5c%2e%2e%25%5c%2e%2e%25%5c%2e%2e%25%5c%2e%2e%25%5c%2e%2e%25%5c%2e%2e%25%5c%2e%2e%25%5c%2e%2e%25%5c%2e%2e%%20%20%20%2025%5c%2e%2e%25%5c%2e%2e%255cboot%2eini&tenantKey=61&timeRangeScalar=1&timeRangeField=hours&timeRangeType=Last&timeRangeStart=&timeRangeEnd=&indexes=&filters=&resultSize=30\"}',\n",
       "       '{\"searchText=&tenantKey=61&timeRangeScalar=1&timeRangeField=hours&timeRangeType=Last&timeRangeStart=&timeRangeEnd=&indexes=&filters=%2f%2e%2f%5c%2f%2e%2f%2e%2f%5c%2f%2e%2f%2e%2f%5c%2f%2e%2f%7bFILE%7d&resultSize=30\"}'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess dataset\n",
    "X = dataset[:,0]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 1, 1], dtype=object)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = dataset[:,1]\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for index, item in enumerate(X):\n",
    "#        # Quick hack to space out json elements\n",
    "#        reqJson = json.loads(item, object_pairs_hook=OrderedDict)\n",
    "#        del reqJson['contentLength']\n",
    "#        del reqJson['cacheControl']\n",
    "#        del reqJson['index']\n",
    "#        del reqJson['label']\n",
    "#        X[index] = json.dumps(reqJson, separators=(',', ':'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters='\\t\\n', char_level=True)\n",
    "tokenizer.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!': 77,\n",
       " '\"': 31,\n",
       " '#': 70,\n",
       " '$': 83,\n",
       " '%': 10,\n",
       " '&': 7,\n",
       " \"'\": 58,\n",
       " '(': 55,\n",
       " ')': 52,\n",
       " '*': 84,\n",
       " '+': 37,\n",
       " ',': 59,\n",
       " '-': 56,\n",
       " '.': 62,\n",
       " '0': 21,\n",
       " '1': 20,\n",
       " '2': 14,\n",
       " '3': 25,\n",
       " '4': 43,\n",
       " '5': 36,\n",
       " '6': 32,\n",
       " '7': 44,\n",
       " '8': 46,\n",
       " '9': 45,\n",
       " '=': 4,\n",
       " '@': 82,\n",
       " 'A': 23,\n",
       " 'B': 48,\n",
       " 'C': 47,\n",
       " 'D': 60,\n",
       " 'E': 34,\n",
       " 'F': 35,\n",
       " 'G': 68,\n",
       " 'H': 72,\n",
       " 'I': 57,\n",
       " 'J': 73,\n",
       " 'K': 39,\n",
       " 'L': 33,\n",
       " 'M': 53,\n",
       " 'N': 54,\n",
       " 'O': 69,\n",
       " 'P': 65,\n",
       " 'Q': 76,\n",
       " 'R': 17,\n",
       " 'S': 22,\n",
       " 'T': 29,\n",
       " 'U': 61,\n",
       " 'V': 64,\n",
       " 'W': 79,\n",
       " 'X': 71,\n",
       " 'Y': 78,\n",
       " 'Z': 75,\n",
       " '[': 80,\n",
       " '\\\\': 51,\n",
       " ']': 81,\n",
       " '_': 67,\n",
       " 'a': 2,\n",
       " 'b': 42,\n",
       " 'c': 16,\n",
       " 'd': 15,\n",
       " 'e': 1,\n",
       " 'f': 19,\n",
       " 'g': 13,\n",
       " 'h': 26,\n",
       " 'i': 5,\n",
       " 'j': 63,\n",
       " 'k': 66,\n",
       " 'l': 12,\n",
       " 'm': 11,\n",
       " 'n': 6,\n",
       " 'o': 18,\n",
       " 'p': 27,\n",
       " 'q': 74,\n",
       " 'r': 8,\n",
       " 's': 9,\n",
       " 't': 3,\n",
       " 'u': 24,\n",
       " 'v': 49,\n",
       " 'w': 50,\n",
       " 'x': 28,\n",
       " 'y': 30,\n",
       " 'z': 38,\n",
       " '{': 40,\n",
       " '}': 41,\n",
       " '~': 85}"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and save word dictionary\n",
    "word_dict_file = 'build/word-dictionary.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.dirname(word_dict_file)):\n",
    "    os.makedirs(os.path.dirname(word_dict_file))\n",
    "\n",
    "with open(word_dict_file, 'w') as outfile:\n",
    "    json.dump(tokenizer.word_index, outfile, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words = len(tokenizer.word_index)+1\n",
    "num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tokenizer.texts_to_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_log_length = 1024\n",
    "train_size = int(len(dataset) * .75)\n",
    "\n",
    "X_processed = sequence.pad_sequences(X, maxlen=max_log_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training set and a temporary set using sklearn.model_selection.traing_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=23)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_processed = sequence.pad_sequences(X, maxlen=max_log_length)\n",
    "X_train, X_test = X_processed[0:train_size], X_processed[train_size:len(X_processed)]\n",
    "Y_train, Y_test = Y[0:train_size], Y[train_size:len(Y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_callback = TensorBoard(log_dir='./logs', embeddings_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, dropout=0.2, return_sequences=True, recurrent_dropout=0.2)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 1024, 32)          2752      \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 1024, 64)          24832     \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 60,673\n",
      "Trainable params: 60,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 8118 samples, validate on 2706 samples\n",
      "Epoch 1/5\n",
      "8118/8118 [==============================] - 253s 31ms/step - loss: 0.6076 - acc: 0.6590 - val_loss: 0.4880 - val_acc: 0.7676\n",
      "Epoch 2/5\n",
      "8118/8118 [==============================] - 247s 30ms/step - loss: 0.4602 - acc: 0.7826 - val_loss: 0.2296 - val_acc: 0.9194\n",
      "Epoch 3/5\n",
      "8118/8118 [==============================] - 247s 30ms/step - loss: 0.2161 - acc: 0.9426 - val_loss: 0.2338 - val_acc: 0.9379\n",
      "Epoch 4/5\n",
      "8118/8118 [==============================] - 245s 30ms/step - loss: 0.1399 - acc: 0.9670 - val_loss: 0.1322 - val_acc: 0.9745\n",
      "Epoch 5/5\n",
      "8118/8118 [==============================] - 248s 31ms/step - loss: 0.1323 - acc: 0.9699 - val_loss: 0.0711 - val_acc: 0.9845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f375b98c978>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(num_words, 32, input_length=max_log_length))\n",
    "\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(LSTM(64, recurrent_dropout=0.5))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(LSTM(64, dropout_U = 0.2, dropout_W = 0.2, return_sequences=True))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, Y_train, validation_split=0.25, epochs=5, batch_size=128, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3608/3608 [==============================] - 23s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "score, acc = model.evaluate(numpy.array(X_test), numpy.array(Y_test), verbose=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 98.20%\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Accuracy: {:0.2f}%\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save_weights('model-weights.h5')\n",
    "model.save('model.h5')\n",
    "with open('model.json', 'w') as outfile:\n",
    "    outfile.write(model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0 ...  4 14 21]]\n",
      "[[0]]\n",
      "[[0.07512387]]\n"
     ]
    }
   ],
   "source": [
    "X_prediction = tokenizer.texts_to_sequences([\"searchText=test=123&filters=test&resultSize=20\"])\n",
    "X_prediction_processed = sequence.pad_sequences(X_prediction, maxlen=max_log_length)\n",
    "print(X_prediction_processed)\n",
    "\n",
    "prediction = model.predict_classes(X_prediction_processed, verbose=0)\n",
    "prediction_proba = model.predict_proba(X_prediction_processed, verbose=0)\n",
    "#model.predict(X)\n",
    "#model.predict_proba(X)\n",
    "print(prediction)\n",
    "print(prediction_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
